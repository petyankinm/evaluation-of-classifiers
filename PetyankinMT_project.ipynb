{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score as asc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считываем и обрабатываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.132786</td>\n",
       "      <td>0.079557</td>\n",
       "      <td>0.119090</td>\n",
       "      <td>0.067958</td>\n",
       "      <td>0.209592</td>\n",
       "      <td>0.141634</td>\n",
       "      <td>1.932562</td>\n",
       "      <td>8.308895</td>\n",
       "      <td>0.963181</td>\n",
       "      <td>0.738307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132786</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.298222</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.726562</td>\n",
       "      <td>2.718750</td>\n",
       "      <td>0.125160</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.150762</td>\n",
       "      <td>0.074463</td>\n",
       "      <td>0.160106</td>\n",
       "      <td>0.092899</td>\n",
       "      <td>0.205718</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>1.530643</td>\n",
       "      <td>5.987498</td>\n",
       "      <td>0.967573</td>\n",
       "      <td>0.762638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150762</td>\n",
       "      <td>0.105945</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.479620</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.312500</td>\n",
       "      <td>5.304688</td>\n",
       "      <td>0.123992</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.076767</td>\n",
       "      <td>0.144337</td>\n",
       "      <td>0.110532</td>\n",
       "      <td>0.231962</td>\n",
       "      <td>0.121430</td>\n",
       "      <td>1.397156</td>\n",
       "      <td>4.766611</td>\n",
       "      <td>0.959255</td>\n",
       "      <td>0.719858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.093052</td>\n",
       "      <td>0.017758</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.301339</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.283937</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.142239</td>\n",
       "      <td>0.078018</td>\n",
       "      <td>0.138587</td>\n",
       "      <td>0.088206</td>\n",
       "      <td>0.208587</td>\n",
       "      <td>0.120381</td>\n",
       "      <td>1.099746</td>\n",
       "      <td>4.070284</td>\n",
       "      <td>0.970723</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142239</td>\n",
       "      <td>0.096729</td>\n",
       "      <td>0.017957</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.336476</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.164062</td>\n",
       "      <td>2.156250</td>\n",
       "      <td>0.148272</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.134329</td>\n",
       "      <td>0.080350</td>\n",
       "      <td>0.121451</td>\n",
       "      <td>0.075580</td>\n",
       "      <td>0.201957</td>\n",
       "      <td>0.126377</td>\n",
       "      <td>1.190368</td>\n",
       "      <td>4.787310</td>\n",
       "      <td>0.975246</td>\n",
       "      <td>0.804505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134329</td>\n",
       "      <td>0.105881</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.340365</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4.695312</td>\n",
       "      <td>4.679688</td>\n",
       "      <td>0.089920</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.157021</td>\n",
       "      <td>0.071943</td>\n",
       "      <td>0.168160</td>\n",
       "      <td>0.101430</td>\n",
       "      <td>0.216740</td>\n",
       "      <td>0.115310</td>\n",
       "      <td>0.979442</td>\n",
       "      <td>3.974223</td>\n",
       "      <td>0.965249</td>\n",
       "      <td>0.733693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157021</td>\n",
       "      <td>0.088894</td>\n",
       "      <td>0.022069</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.460227</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>2.804688</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.138551</td>\n",
       "      <td>0.077054</td>\n",
       "      <td>0.127527</td>\n",
       "      <td>0.087314</td>\n",
       "      <td>0.202739</td>\n",
       "      <td>0.115426</td>\n",
       "      <td>1.626770</td>\n",
       "      <td>6.291365</td>\n",
       "      <td>0.966004</td>\n",
       "      <td>0.752042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138551</td>\n",
       "      <td>0.104199</td>\n",
       "      <td>0.019139</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.718750</td>\n",
       "      <td>2.710938</td>\n",
       "      <td>0.132351</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.137343</td>\n",
       "      <td>0.080877</td>\n",
       "      <td>0.124263</td>\n",
       "      <td>0.083145</td>\n",
       "      <td>0.209227</td>\n",
       "      <td>0.126082</td>\n",
       "      <td>1.378728</td>\n",
       "      <td>5.008952</td>\n",
       "      <td>0.963514</td>\n",
       "      <td>0.736150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137343</td>\n",
       "      <td>0.092644</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.481671</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>5.015625</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.181225</td>\n",
       "      <td>0.060042</td>\n",
       "      <td>0.190953</td>\n",
       "      <td>0.128839</td>\n",
       "      <td>0.229532</td>\n",
       "      <td>0.100693</td>\n",
       "      <td>1.369430</td>\n",
       "      <td>5.475600</td>\n",
       "      <td>0.937446</td>\n",
       "      <td>0.537080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181225</td>\n",
       "      <td>0.131504</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.277114</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.804688</td>\n",
       "      <td>2.796875</td>\n",
       "      <td>0.416550</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.183115</td>\n",
       "      <td>0.066982</td>\n",
       "      <td>0.191233</td>\n",
       "      <td>0.129149</td>\n",
       "      <td>0.240152</td>\n",
       "      <td>0.111004</td>\n",
       "      <td>3.568104</td>\n",
       "      <td>35.384748</td>\n",
       "      <td>0.940333</td>\n",
       "      <td>0.571394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183115</td>\n",
       "      <td>0.102799</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.245739</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>6.742188</td>\n",
       "      <td>6.539062</td>\n",
       "      <td>0.139332</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.174272</td>\n",
       "      <td>0.069411</td>\n",
       "      <td>0.190874</td>\n",
       "      <td>0.115602</td>\n",
       "      <td>0.228279</td>\n",
       "      <td>0.112677</td>\n",
       "      <td>4.485038</td>\n",
       "      <td>61.764908</td>\n",
       "      <td>0.950972</td>\n",
       "      <td>0.635199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174272</td>\n",
       "      <td>0.102046</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>1.621299</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.992188</td>\n",
       "      <td>0.209311</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.190846</td>\n",
       "      <td>0.065790</td>\n",
       "      <td>0.207951</td>\n",
       "      <td>0.132280</td>\n",
       "      <td>0.244357</td>\n",
       "      <td>0.112076</td>\n",
       "      <td>1.562304</td>\n",
       "      <td>7.834350</td>\n",
       "      <td>0.938546</td>\n",
       "      <td>0.538810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190846</td>\n",
       "      <td>0.113323</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.434115</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>6.320312</td>\n",
       "      <td>6.312500</td>\n",
       "      <td>0.254780</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.171247</td>\n",
       "      <td>0.074872</td>\n",
       "      <td>0.152807</td>\n",
       "      <td>0.122391</td>\n",
       "      <td>0.243617</td>\n",
       "      <td>0.121227</td>\n",
       "      <td>3.207170</td>\n",
       "      <td>25.765565</td>\n",
       "      <td>0.936954</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171247</td>\n",
       "      <td>0.079718</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.106279</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.138355</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.168346</td>\n",
       "      <td>0.074121</td>\n",
       "      <td>0.145618</td>\n",
       "      <td>0.115756</td>\n",
       "      <td>0.239824</td>\n",
       "      <td>0.124068</td>\n",
       "      <td>2.704335</td>\n",
       "      <td>18.484703</td>\n",
       "      <td>0.934523</td>\n",
       "      <td>0.559742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168346</td>\n",
       "      <td>0.083484</td>\n",
       "      <td>0.015717</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.146563</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>3.117188</td>\n",
       "      <td>0.059537</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.173631</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>0.153569</td>\n",
       "      <td>0.123680</td>\n",
       "      <td>0.244234</td>\n",
       "      <td>0.120554</td>\n",
       "      <td>2.804975</td>\n",
       "      <td>20.857543</td>\n",
       "      <td>0.930917</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173631</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.193044</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.820312</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>0.068124</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.172754</td>\n",
       "      <td>0.076903</td>\n",
       "      <td>0.177736</td>\n",
       "      <td>0.120070</td>\n",
       "      <td>0.245368</td>\n",
       "      <td>0.125298</td>\n",
       "      <td>2.967765</td>\n",
       "      <td>20.078115</td>\n",
       "      <td>0.925539</td>\n",
       "      <td>0.523081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172754</td>\n",
       "      <td>0.093574</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.235877</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.235069</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.181015</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.169299</td>\n",
       "      <td>0.128673</td>\n",
       "      <td>0.254175</td>\n",
       "      <td>0.125502</td>\n",
       "      <td>2.587325</td>\n",
       "      <td>12.281432</td>\n",
       "      <td>0.915284</td>\n",
       "      <td>0.475317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181015</td>\n",
       "      <td>0.098643</td>\n",
       "      <td>0.016145</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.695312</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.163536</td>\n",
       "      <td>0.072449</td>\n",
       "      <td>0.145543</td>\n",
       "      <td>0.113930</td>\n",
       "      <td>0.227449</td>\n",
       "      <td>0.113519</td>\n",
       "      <td>3.587650</td>\n",
       "      <td>28.653781</td>\n",
       "      <td>0.927015</td>\n",
       "      <td>0.542422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163536</td>\n",
       "      <td>0.062542</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.197531</td>\n",
       "      <td>0.059622</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.091699</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.075105</td>\n",
       "      <td>0.146053</td>\n",
       "      <td>0.123989</td>\n",
       "      <td>0.250126</td>\n",
       "      <td>0.126137</td>\n",
       "      <td>2.816793</td>\n",
       "      <td>13.764582</td>\n",
       "      <td>0.913832</td>\n",
       "      <td>0.487966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.077698</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.161791</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.160422</td>\n",
       "      <td>0.076615</td>\n",
       "      <td>0.144824</td>\n",
       "      <td>0.120924</td>\n",
       "      <td>0.237244</td>\n",
       "      <td>0.116319</td>\n",
       "      <td>6.253208</td>\n",
       "      <td>85.491926</td>\n",
       "      <td>0.933030</td>\n",
       "      <td>0.567424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160422</td>\n",
       "      <td>0.098944</td>\n",
       "      <td>0.016097</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.206756</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.953125</td>\n",
       "      <td>3.945312</td>\n",
       "      <td>0.073890</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.164700</td>\n",
       "      <td>0.075362</td>\n",
       "      <td>0.147018</td>\n",
       "      <td>0.118698</td>\n",
       "      <td>0.240475</td>\n",
       "      <td>0.121777</td>\n",
       "      <td>4.208608</td>\n",
       "      <td>43.681885</td>\n",
       "      <td>0.940669</td>\n",
       "      <td>0.604020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164700</td>\n",
       "      <td>0.082963</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.143353</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>1.054688</td>\n",
       "      <td>0.125926</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.169579</td>\n",
       "      <td>0.075635</td>\n",
       "      <td>0.186468</td>\n",
       "      <td>0.116706</td>\n",
       "      <td>0.238549</td>\n",
       "      <td>0.121843</td>\n",
       "      <td>4.269923</td>\n",
       "      <td>45.895248</td>\n",
       "      <td>0.929498</td>\n",
       "      <td>0.543709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169579</td>\n",
       "      <td>0.082451</td>\n",
       "      <td>0.016211</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.609375</td>\n",
       "      <td>3.601562</td>\n",
       "      <td>0.050841</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.169021</td>\n",
       "      <td>0.071778</td>\n",
       "      <td>0.143168</td>\n",
       "      <td>0.125801</td>\n",
       "      <td>0.248315</td>\n",
       "      <td>0.122515</td>\n",
       "      <td>3.079273</td>\n",
       "      <td>14.340299</td>\n",
       "      <td>0.902275</td>\n",
       "      <td>0.477746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169021</td>\n",
       "      <td>0.130598</td>\n",
       "      <td>0.015842</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.335313</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.397354</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.072841</td>\n",
       "      <td>0.141739</td>\n",
       "      <td>0.122174</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.117826</td>\n",
       "      <td>2.192126</td>\n",
       "      <td>8.152410</td>\n",
       "      <td>0.913763</td>\n",
       "      <td>0.539479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.120052</td>\n",
       "      <td>0.016244</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.298678</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.384778</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.180528</td>\n",
       "      <td>0.070867</td>\n",
       "      <td>0.142385</td>\n",
       "      <td>0.129541</td>\n",
       "      <td>0.252477</td>\n",
       "      <td>0.122936</td>\n",
       "      <td>2.799969</td>\n",
       "      <td>12.190361</td>\n",
       "      <td>0.853115</td>\n",
       "      <td>0.313426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180528</td>\n",
       "      <td>0.126607</td>\n",
       "      <td>0.017039</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.234863</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.329241</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>0.114477</td>\n",
       "      <td>0.081973</td>\n",
       "      <td>0.090199</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.158806</td>\n",
       "      <td>1.103680</td>\n",
       "      <td>3.759184</td>\n",
       "      <td>0.954130</td>\n",
       "      <td>0.689347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114477</td>\n",
       "      <td>0.189394</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.566840</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.273438</td>\n",
       "      <td>4.265625</td>\n",
       "      <td>0.183258</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>0.112769</td>\n",
       "      <td>0.074424</td>\n",
       "      <td>0.094248</td>\n",
       "      <td>0.049183</td>\n",
       "      <td>0.183235</td>\n",
       "      <td>0.134052</td>\n",
       "      <td>0.945953</td>\n",
       "      <td>3.290904</td>\n",
       "      <td>0.965719</td>\n",
       "      <td>0.742464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112769</td>\n",
       "      <td>0.169836</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.877604</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.937500</td>\n",
       "      <td>4.929688</td>\n",
       "      <td>0.171708</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>0.126439</td>\n",
       "      <td>0.079412</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>0.046889</td>\n",
       "      <td>0.198993</td>\n",
       "      <td>0.152103</td>\n",
       "      <td>1.452173</td>\n",
       "      <td>5.582106</td>\n",
       "      <td>0.971946</td>\n",
       "      <td>0.790175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126439</td>\n",
       "      <td>0.179613</td>\n",
       "      <td>0.029575</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.614110</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.914062</td>\n",
       "      <td>4.906250</td>\n",
       "      <td>0.090045</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>0.117350</td>\n",
       "      <td>0.090035</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>0.024017</td>\n",
       "      <td>0.203946</td>\n",
       "      <td>0.179929</td>\n",
       "      <td>2.610623</td>\n",
       "      <td>12.442898</td>\n",
       "      <td>0.953624</td>\n",
       "      <td>0.701434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>0.178040</td>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.188721</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.277759</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>0.104793</td>\n",
       "      <td>0.085201</td>\n",
       "      <td>0.077886</td>\n",
       "      <td>0.028388</td>\n",
       "      <td>0.186101</td>\n",
       "      <td>0.157712</td>\n",
       "      <td>2.419127</td>\n",
       "      <td>11.281968</td>\n",
       "      <td>0.956977</td>\n",
       "      <td>0.718462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104793</td>\n",
       "      <td>0.183565</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.297953</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.370904</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>0.127633</td>\n",
       "      <td>0.084931</td>\n",
       "      <td>0.158892</td>\n",
       "      <td>0.034531</td>\n",
       "      <td>0.201430</td>\n",
       "      <td>0.166899</td>\n",
       "      <td>1.591174</td>\n",
       "      <td>5.347645</td>\n",
       "      <td>0.949757</td>\n",
       "      <td>0.671247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127633</td>\n",
       "      <td>0.178363</td>\n",
       "      <td>0.058182</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.634014</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>5.031250</td>\n",
       "      <td>5.015625</td>\n",
       "      <td>0.121246</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>0.091250</td>\n",
       "      <td>0.086956</td>\n",
       "      <td>0.048191</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>0.179043</td>\n",
       "      <td>0.163851</td>\n",
       "      <td>3.089787</td>\n",
       "      <td>12.857558</td>\n",
       "      <td>0.930715</td>\n",
       "      <td>0.622816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091250</td>\n",
       "      <td>0.170893</td>\n",
       "      <td>0.016178</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.767314</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.289062</td>\n",
       "      <td>5.281250</td>\n",
       "      <td>0.187912</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>0.082404</td>\n",
       "      <td>0.085136</td>\n",
       "      <td>0.035114</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>0.152827</td>\n",
       "      <td>0.135906</td>\n",
       "      <td>2.570944</td>\n",
       "      <td>9.179264</td>\n",
       "      <td>0.921649</td>\n",
       "      <td>0.576089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082404</td>\n",
       "      <td>0.183387</td>\n",
       "      <td>0.034043</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.328962</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.445053</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>0.124695</td>\n",
       "      <td>0.080989</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>0.042033</td>\n",
       "      <td>0.197268</td>\n",
       "      <td>0.155234</td>\n",
       "      <td>1.970756</td>\n",
       "      <td>8.000504</td>\n",
       "      <td>0.958531</td>\n",
       "      <td>0.721682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124695</td>\n",
       "      <td>0.182513</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.293527</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.396091</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>0.131566</td>\n",
       "      <td>0.084354</td>\n",
       "      <td>0.131889</td>\n",
       "      <td>0.053093</td>\n",
       "      <td>0.196147</td>\n",
       "      <td>0.143055</td>\n",
       "      <td>2.243370</td>\n",
       "      <td>11.544740</td>\n",
       "      <td>0.968324</td>\n",
       "      <td>0.784108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131566</td>\n",
       "      <td>0.191163</td>\n",
       "      <td>0.029144</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.214725</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.351645</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>0.108888</td>\n",
       "      <td>0.092021</td>\n",
       "      <td>0.070063</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>0.201180</td>\n",
       "      <td>0.178660</td>\n",
       "      <td>2.235435</td>\n",
       "      <td>8.528681</td>\n",
       "      <td>0.947621</td>\n",
       "      <td>0.679795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108888</td>\n",
       "      <td>0.160473</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.497721</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.945312</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>0.236240</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>0.090445</td>\n",
       "      <td>0.079045</td>\n",
       "      <td>0.059358</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>0.167727</td>\n",
       "      <td>0.146834</td>\n",
       "      <td>2.187161</td>\n",
       "      <td>8.221164</td>\n",
       "      <td>0.942404</td>\n",
       "      <td>0.628992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090445</td>\n",
       "      <td>0.182431</td>\n",
       "      <td>0.026622</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.735453</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.531250</td>\n",
       "      <td>5.523438</td>\n",
       "      <td>0.170489</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>0.137507</td>\n",
       "      <td>0.091521</td>\n",
       "      <td>0.161298</td>\n",
       "      <td>0.043547</td>\n",
       "      <td>0.221260</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>1.119608</td>\n",
       "      <td>4.185207</td>\n",
       "      <td>0.967706</td>\n",
       "      <td>0.739008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137507</td>\n",
       "      <td>0.190093</td>\n",
       "      <td>0.019116</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.354367</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.117188</td>\n",
       "      <td>3.109375</td>\n",
       "      <td>0.096069</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151</th>\n",
       "      <td>0.113148</td>\n",
       "      <td>0.090335</td>\n",
       "      <td>0.084335</td>\n",
       "      <td>0.026622</td>\n",
       "      <td>0.198830</td>\n",
       "      <td>0.172207</td>\n",
       "      <td>2.258273</td>\n",
       "      <td>9.579337</td>\n",
       "      <td>0.957433</td>\n",
       "      <td>0.717683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113148</td>\n",
       "      <td>0.187444</td>\n",
       "      <td>0.023495</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.622489</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.898438</td>\n",
       "      <td>4.890625</td>\n",
       "      <td>0.128717</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>0.149731</td>\n",
       "      <td>0.082852</td>\n",
       "      <td>0.180932</td>\n",
       "      <td>0.060212</td>\n",
       "      <td>0.219788</td>\n",
       "      <td>0.159576</td>\n",
       "      <td>1.240037</td>\n",
       "      <td>4.019385</td>\n",
       "      <td>0.949787</td>\n",
       "      <td>0.652936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149731</td>\n",
       "      <td>0.183974</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>1.361213</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>6.031250</td>\n",
       "      <td>5.828125</td>\n",
       "      <td>0.365700</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>0.189614</td>\n",
       "      <td>0.035933</td>\n",
       "      <td>0.194116</td>\n",
       "      <td>0.168434</td>\n",
       "      <td>0.205289</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>2.724415</td>\n",
       "      <td>10.986864</td>\n",
       "      <td>0.871215</td>\n",
       "      <td>0.236684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189614</td>\n",
       "      <td>0.163059</td>\n",
       "      <td>0.029685</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>1.370192</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.835938</td>\n",
       "      <td>0.235948</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>0.200097</td>\n",
       "      <td>0.045533</td>\n",
       "      <td>0.203796</td>\n",
       "      <td>0.176581</td>\n",
       "      <td>0.232133</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>1.160197</td>\n",
       "      <td>3.733815</td>\n",
       "      <td>0.919607</td>\n",
       "      <td>0.357144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200097</td>\n",
       "      <td>0.168531</td>\n",
       "      <td>0.063241</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.851562</td>\n",
       "      <td>0.092208</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>0.178573</td>\n",
       "      <td>0.046679</td>\n",
       "      <td>0.164388</td>\n",
       "      <td>0.149309</td>\n",
       "      <td>0.204601</td>\n",
       "      <td>0.055293</td>\n",
       "      <td>3.066668</td>\n",
       "      <td>15.684088</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.321169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178573</td>\n",
       "      <td>0.155380</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.637921</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>6.148438</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.101291</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>0.201806</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>0.201622</td>\n",
       "      <td>0.178165</td>\n",
       "      <td>0.227872</td>\n",
       "      <td>0.049707</td>\n",
       "      <td>1.585353</td>\n",
       "      <td>4.945634</td>\n",
       "      <td>0.884731</td>\n",
       "      <td>0.227903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201806</td>\n",
       "      <td>0.191704</td>\n",
       "      <td>0.032720</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.921875</td>\n",
       "      <td>5.914062</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>0.203627</td>\n",
       "      <td>0.041529</td>\n",
       "      <td>0.204104</td>\n",
       "      <td>0.175661</td>\n",
       "      <td>0.239122</td>\n",
       "      <td>0.063461</td>\n",
       "      <td>1.462972</td>\n",
       "      <td>4.790370</td>\n",
       "      <td>0.903458</td>\n",
       "      <td>0.246953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203627</td>\n",
       "      <td>0.146783</td>\n",
       "      <td>0.020566</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.875558</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>6.898438</td>\n",
       "      <td>6.726562</td>\n",
       "      <td>0.145534</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.040607</td>\n",
       "      <td>0.182534</td>\n",
       "      <td>0.156480</td>\n",
       "      <td>0.207646</td>\n",
       "      <td>0.051166</td>\n",
       "      <td>2.054138</td>\n",
       "      <td>7.483019</td>\n",
       "      <td>0.898138</td>\n",
       "      <td>0.313925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.149237</td>\n",
       "      <td>0.018648</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.550312</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.421875</td>\n",
       "      <td>3.414062</td>\n",
       "      <td>0.166503</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>0.168794</td>\n",
       "      <td>0.085842</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.095558</td>\n",
       "      <td>0.240229</td>\n",
       "      <td>0.144671</td>\n",
       "      <td>1.462248</td>\n",
       "      <td>5.077956</td>\n",
       "      <td>0.956201</td>\n",
       "      <td>0.706861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168794</td>\n",
       "      <td>0.182863</td>\n",
       "      <td>0.020699</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.882812</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>0.268617</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>0.151771</td>\n",
       "      <td>0.089147</td>\n",
       "      <td>0.185970</td>\n",
       "      <td>0.058159</td>\n",
       "      <td>0.230199</td>\n",
       "      <td>0.172040</td>\n",
       "      <td>1.227710</td>\n",
       "      <td>4.304354</td>\n",
       "      <td>0.962045</td>\n",
       "      <td>0.744590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151771</td>\n",
       "      <td>0.201600</td>\n",
       "      <td>0.023426</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.766741</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.007812</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.192220</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>0.170656</td>\n",
       "      <td>0.081237</td>\n",
       "      <td>0.184277</td>\n",
       "      <td>0.113012</td>\n",
       "      <td>0.239096</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>1.378256</td>\n",
       "      <td>5.431663</td>\n",
       "      <td>0.950750</td>\n",
       "      <td>0.658558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170656</td>\n",
       "      <td>0.198475</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.336918</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>0.146023</td>\n",
       "      <td>0.092525</td>\n",
       "      <td>0.183434</td>\n",
       "      <td>0.041747</td>\n",
       "      <td>0.224337</td>\n",
       "      <td>0.182590</td>\n",
       "      <td>1.384981</td>\n",
       "      <td>5.118927</td>\n",
       "      <td>0.948999</td>\n",
       "      <td>0.659825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146023</td>\n",
       "      <td>0.195640</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.533854</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.992188</td>\n",
       "      <td>2.984375</td>\n",
       "      <td>0.258924</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.095798</td>\n",
       "      <td>0.183731</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.224360</td>\n",
       "      <td>0.190936</td>\n",
       "      <td>1.876502</td>\n",
       "      <td>6.604509</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.654196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.209918</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.494271</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>0.194759</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>0.219943</td>\n",
       "      <td>0.176435</td>\n",
       "      <td>1.591065</td>\n",
       "      <td>5.388298</td>\n",
       "      <td>0.950436</td>\n",
       "      <td>0.675470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.172375</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.791360</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>3.585938</td>\n",
       "      <td>0.311002</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0     0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1     0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2     0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3     0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4     0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "5     0.132786  0.079557  0.119090  0.067958  0.209592  0.141634   1.932562   \n",
       "6     0.150762  0.074463  0.160106  0.092899  0.205718  0.112819   1.530643   \n",
       "7     0.160514  0.076767  0.144337  0.110532  0.231962  0.121430   1.397156   \n",
       "8     0.142239  0.078018  0.138587  0.088206  0.208587  0.120381   1.099746   \n",
       "9     0.134329  0.080350  0.121451  0.075580  0.201957  0.126377   1.190368   \n",
       "10    0.157021  0.071943  0.168160  0.101430  0.216740  0.115310   0.979442   \n",
       "11    0.138551  0.077054  0.127527  0.087314  0.202739  0.115426   1.626770   \n",
       "12    0.137343  0.080877  0.124263  0.083145  0.209227  0.126082   1.378728   \n",
       "13    0.181225  0.060042  0.190953  0.128839  0.229532  0.100693   1.369430   \n",
       "14    0.183115  0.066982  0.191233  0.129149  0.240152  0.111004   3.568104   \n",
       "15    0.174272  0.069411  0.190874  0.115602  0.228279  0.112677   4.485038   \n",
       "16    0.190846  0.065790  0.207951  0.132280  0.244357  0.112076   1.562304   \n",
       "17    0.171247  0.074872  0.152807  0.122391  0.243617  0.121227   3.207170   \n",
       "18    0.168346  0.074121  0.145618  0.115756  0.239824  0.124068   2.704335   \n",
       "19    0.173631  0.073352  0.153569  0.123680  0.244234  0.120554   2.804975   \n",
       "20    0.172754  0.076903  0.177736  0.120070  0.245368  0.125298   2.967765   \n",
       "21    0.181015  0.074369  0.169299  0.128673  0.254175  0.125502   2.587325   \n",
       "22    0.163536  0.072449  0.145543  0.113930  0.227449  0.113519   3.587650   \n",
       "23    0.170213  0.075105  0.146053  0.123989  0.250126  0.126137   2.816793   \n",
       "24    0.160422  0.076615  0.144824  0.120924  0.237244  0.116319   6.253208   \n",
       "25    0.164700  0.075362  0.147018  0.118698  0.240475  0.121777   4.208608   \n",
       "26    0.169579  0.075635  0.186468  0.116706  0.238549  0.121843   4.269923   \n",
       "27    0.169021  0.071778  0.143168  0.125801  0.248315  0.122515   3.079273   \n",
       "28    0.167340  0.072841  0.141739  0.122174  0.240000  0.117826   2.192126   \n",
       "29    0.180528  0.070867  0.142385  0.129541  0.252477  0.122936   2.799969   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "3138  0.114477  0.081973  0.090199  0.041095  0.199900  0.158806   1.103680   \n",
       "3139  0.112769  0.074424  0.094248  0.049183  0.183235  0.134052   0.945953   \n",
       "3140  0.126439  0.079412  0.127325  0.046889  0.198993  0.152103   1.452173   \n",
       "3141  0.117350  0.090035  0.109478  0.024017  0.203946  0.179929   2.610623   \n",
       "3142  0.104793  0.085201  0.077886  0.028388  0.186101  0.157712   2.419127   \n",
       "3143  0.127633  0.084931  0.158892  0.034531  0.201430  0.166899   1.591174   \n",
       "3144  0.091250  0.086956  0.048191  0.015193  0.179043  0.163851   3.089787   \n",
       "3145  0.082404  0.085136  0.035114  0.016920  0.152827  0.135906   2.570944   \n",
       "3146  0.124695  0.080989  0.131882  0.042033  0.197268  0.155234   1.970756   \n",
       "3147  0.131566  0.084354  0.131889  0.053093  0.196147  0.143055   2.243370   \n",
       "3148  0.108888  0.092021  0.070063  0.022520  0.201180  0.178660   2.235435   \n",
       "3149  0.090445  0.079045  0.059358  0.020893  0.167727  0.146834   2.187161   \n",
       "3150  0.137507  0.091521  0.161298  0.043547  0.221260  0.177713   1.119608   \n",
       "3151  0.113148  0.090335  0.084335  0.026622  0.198830  0.172207   2.258273   \n",
       "3152  0.149731  0.082852  0.180932  0.060212  0.219788  0.159576   1.240037   \n",
       "3153  0.189614  0.035933  0.194116  0.168434  0.205289  0.036855   2.724415   \n",
       "3154  0.200097  0.045533  0.203796  0.176581  0.232133  0.055552   1.160197   \n",
       "3155  0.178573  0.046679  0.164388  0.149309  0.204601  0.055293   3.066668   \n",
       "3156  0.201806  0.036057  0.201622  0.178165  0.227872  0.049707   1.585353   \n",
       "3157  0.203627  0.041529  0.204104  0.175661  0.239122  0.063461   1.462972   \n",
       "3158  0.183667  0.040607  0.182534  0.156480  0.207646  0.051166   2.054138   \n",
       "3159  0.168794  0.085842  0.188980  0.095558  0.240229  0.144671   1.462248   \n",
       "3160  0.151771  0.089147  0.185970  0.058159  0.230199  0.172040   1.227710   \n",
       "3161  0.170656  0.081237  0.184277  0.113012  0.239096  0.126084   1.378256   \n",
       "3162  0.146023  0.092525  0.183434  0.041747  0.224337  0.182590   1.384981   \n",
       "3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
       "3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
       "3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936   1.876502   \n",
       "3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435   1.591065   \n",
       "3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
       "\n",
       "             kurt    sp.ent       sfm   ...    centroid   meanfun    minfun  \\\n",
       "0      274.402906  0.893369  0.491918   ...    0.059781  0.084279  0.015702   \n",
       "1      634.613855  0.892193  0.513724   ...    0.066009  0.107937  0.015826   \n",
       "2     1024.927705  0.846389  0.478905   ...    0.077316  0.098706  0.015656   \n",
       "3        4.177296  0.963322  0.727232   ...    0.151228  0.088965  0.017798   \n",
       "4        4.333713  0.971955  0.783568   ...    0.135120  0.106398  0.016931   \n",
       "5        8.308895  0.963181  0.738307   ...    0.132786  0.110132  0.017112   \n",
       "6        5.987498  0.967573  0.762638   ...    0.150762  0.105945  0.026230   \n",
       "7        4.766611  0.959255  0.719858   ...    0.160514  0.093052  0.017758   \n",
       "8        4.070284  0.970723  0.770992   ...    0.142239  0.096729  0.017957   \n",
       "9        4.787310  0.975246  0.804505   ...    0.134329  0.105881  0.019300   \n",
       "10       3.974223  0.965249  0.733693   ...    0.157021  0.088894  0.022069   \n",
       "11       6.291365  0.966004  0.752042   ...    0.138551  0.104199  0.019139   \n",
       "12       5.008952  0.963514  0.736150   ...    0.137343  0.092644  0.016789   \n",
       "13       5.475600  0.937446  0.537080   ...    0.181225  0.131504  0.025000   \n",
       "14      35.384748  0.940333  0.571394   ...    0.183115  0.102799  0.020833   \n",
       "15      61.764908  0.950972  0.635199   ...    0.174272  0.102046  0.018328   \n",
       "16       7.834350  0.938546  0.538810   ...    0.190846  0.113323  0.017544   \n",
       "17      25.765565  0.936954  0.586420   ...    0.171247  0.079718  0.015671   \n",
       "18      18.484703  0.934523  0.559742   ...    0.168346  0.083484  0.015717   \n",
       "19      20.857543  0.930917  0.518269   ...    0.173631  0.090130  0.015702   \n",
       "20      20.078115  0.925539  0.523081   ...    0.172754  0.093574  0.015764   \n",
       "21      12.281432  0.915284  0.475317   ...    0.181015  0.098643  0.016145   \n",
       "22      28.653781  0.927015  0.542422   ...    0.163536  0.062542  0.015686   \n",
       "23      13.764582  0.913832  0.487966   ...    0.170213  0.077698  0.015702   \n",
       "24      85.491926  0.933030  0.567424   ...    0.160422  0.098944  0.016097   \n",
       "25      43.681885  0.940669  0.604020   ...    0.164700  0.082963  0.015640   \n",
       "26      45.895248  0.929498  0.543709   ...    0.169579  0.082451  0.016211   \n",
       "27      14.340299  0.902275  0.477746   ...    0.169021  0.130598  0.015842   \n",
       "28       8.152410  0.913763  0.539479   ...    0.167340  0.120052  0.016244   \n",
       "29      12.190361  0.853115  0.313426   ...    0.180528  0.126607  0.017039   \n",
       "...           ...       ...       ...   ...         ...       ...       ...   \n",
       "3138     3.759184  0.954130  0.689347   ...    0.114477  0.189394  0.016343   \n",
       "3139     3.290904  0.965719  0.742464   ...    0.112769  0.169836  0.017917   \n",
       "3140     5.582106  0.971946  0.790175   ...    0.126439  0.179613  0.029575   \n",
       "3141    12.442898  0.953624  0.701434   ...    0.117350  0.178040  0.016512   \n",
       "3142    11.281968  0.956977  0.718462   ...    0.104793  0.183565  0.016444   \n",
       "3143     5.347645  0.949757  0.671247   ...    0.127633  0.178363  0.058182   \n",
       "3144    12.857558  0.930715  0.622816   ...    0.091250  0.170893  0.016178   \n",
       "3145     9.179264  0.921649  0.576089   ...    0.082404  0.183387  0.034043   \n",
       "3146     8.000504  0.958531  0.721682   ...    0.124695  0.182513  0.068966   \n",
       "3147    11.544740  0.968324  0.784108   ...    0.131566  0.191163  0.029144   \n",
       "3148     8.528681  0.947621  0.679795   ...    0.108888  0.160473  0.019512   \n",
       "3149     8.221164  0.942404  0.628992   ...    0.090445  0.182431  0.026622   \n",
       "3150     4.185207  0.967706  0.739008   ...    0.137507  0.190093  0.019116   \n",
       "3151     9.579337  0.957433  0.717683   ...    0.113148  0.187444  0.023495   \n",
       "3152     4.019385  0.949787  0.652936   ...    0.149731  0.183974  0.051948   \n",
       "3153    10.986864  0.871215  0.236684   ...    0.189614  0.163059  0.029685   \n",
       "3154     3.733815  0.919607  0.357144   ...    0.200097  0.168531  0.063241   \n",
       "3155    15.684088  0.891448  0.321169   ...    0.178573  0.155380  0.025478   \n",
       "3156     4.945634  0.884731  0.227903   ...    0.201806  0.191704  0.032720   \n",
       "3157     4.790370  0.903458  0.246953   ...    0.203627  0.146783  0.020566   \n",
       "3158     7.483019  0.898138  0.313925   ...    0.183667  0.149237  0.018648   \n",
       "3159     5.077956  0.956201  0.706861   ...    0.168794  0.182863  0.020699   \n",
       "3160     4.304354  0.962045  0.744590   ...    0.151771  0.201600  0.023426   \n",
       "3161     5.431663  0.950750  0.658558   ...    0.170656  0.198475  0.160000   \n",
       "3162     5.118927  0.948999  0.659825   ...    0.146023  0.195640  0.039506   \n",
       "3163     6.630383  0.962934  0.763182   ...    0.131884  0.182790  0.083770   \n",
       "3164     2.503954  0.960716  0.709570   ...    0.116221  0.188980  0.034409   \n",
       "3165     6.604509  0.946854  0.654196   ...    0.142056  0.209918  0.039506   \n",
       "3166     5.388298  0.950436  0.675470   ...    0.143659  0.172375  0.034483   \n",
       "3167     5.769115  0.938829  0.601529   ...    0.165509  0.185607  0.062257   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "0     0.275862  0.007812  0.007812  0.007812  0.000000  0.000000    male  \n",
       "1     0.250000  0.009014  0.007812  0.054688  0.046875  0.052632    male  \n",
       "2     0.271186  0.007990  0.007812  0.015625  0.007812  0.046512    male  \n",
       "3     0.250000  0.201497  0.007812  0.562500  0.554688  0.247119    male  \n",
       "4     0.266667  0.712812  0.007812  5.484375  5.476562  0.208274    male  \n",
       "5     0.253968  0.298222  0.007812  2.726562  2.718750  0.125160    male  \n",
       "6     0.266667  0.479620  0.007812  5.312500  5.304688  0.123992    male  \n",
       "7     0.144144  0.301339  0.007812  0.539062  0.531250  0.283937    male  \n",
       "8     0.250000  0.336476  0.007812  2.164062  2.156250  0.148272    male  \n",
       "9     0.262295  0.340365  0.015625  4.695312  4.679688  0.089920    male  \n",
       "10    0.117647  0.460227  0.007812  2.812500  2.804688  0.200000    male  \n",
       "11    0.262295  0.246094  0.007812  2.718750  2.710938  0.132351    male  \n",
       "12    0.213333  0.481671  0.015625  5.015625  5.000000  0.088500    male  \n",
       "13    0.275862  1.277114  0.007812  2.804688  2.796875  0.416550    male  \n",
       "14    0.275862  1.245739  0.203125  6.742188  6.539062  0.139332    male  \n",
       "15    0.246154  1.621299  0.007812  7.000000  6.992188  0.209311    male  \n",
       "16    0.275862  1.434115  0.007812  6.320312  6.312500  0.254780    male  \n",
       "17    0.262295  0.106279  0.007812  0.570312  0.562500  0.138355    male  \n",
       "18    0.231884  0.146563  0.007812  3.125000  3.117188  0.059537    male  \n",
       "19    0.210526  0.193044  0.007812  2.820312  2.812500  0.068124    male  \n",
       "20    0.200000  0.235877  0.007812  0.718750  0.710938  0.235069    male  \n",
       "21    0.275862  0.209844  0.007812  3.695312  3.687500  0.059940    male  \n",
       "22    0.197531  0.059622  0.007812  0.445312  0.437500  0.091699    male  \n",
       "23    0.192771  0.101562  0.007812  0.562500  0.554688  0.161791    male  \n",
       "24    0.275862  0.206756  0.007812  3.953125  3.945312  0.073890    male  \n",
       "25    0.253968  0.143353  0.007812  1.062500  1.054688  0.125926    male  \n",
       "26    0.271186  0.148438  0.007812  3.609375  3.601562  0.050841    male  \n",
       "27    0.225352  0.335313  0.007812  0.710938  0.703125  0.397354    male  \n",
       "28    0.262295  0.298678  0.007812  0.679688  0.671875  0.384778    male  \n",
       "29    0.177778  0.234863  0.007812  0.507812  0.500000  0.329241    male  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "3138  0.271186  0.566840  0.007812  4.273438  4.265625  0.183258  female  \n",
       "3139  0.262295  0.877604  0.007812  4.937500  4.929688  0.171708  female  \n",
       "3140  0.266667  0.614110  0.007812  4.914062  4.906250  0.090045  female  \n",
       "3141  0.271186  0.188721  0.007812  0.750000  0.742188  0.277759  female  \n",
       "3142  0.275862  0.297953  0.007812  0.859375  0.851562  0.370904  female  \n",
       "3143  0.271186  0.634014  0.015625  5.031250  5.015625  0.121246  female  \n",
       "3144  0.275862  0.767314  0.007812  5.289062  5.281250  0.187912  female  \n",
       "3145  0.275862  0.328962  0.007812  0.750000  0.742188  0.445053  female  \n",
       "3146  0.238806  0.293527  0.007812  0.851562  0.843750  0.396091  female  \n",
       "3147  0.275862  0.214725  0.007812  0.796875  0.789062  0.351645  female  \n",
       "3148  0.275862  0.497721  0.007812  2.945312  2.937500  0.236240  female  \n",
       "3149  0.258065  0.735453  0.007812  5.531250  5.523438  0.170489  female  \n",
       "3150  0.275862  0.354367  0.007812  3.117188  3.109375  0.096069  female  \n",
       "3151  0.262295  0.622489  0.007812  4.898438  4.890625  0.128717  female  \n",
       "3152  0.253968  1.361213  0.203125  6.031250  5.828125  0.365700  female  \n",
       "3153  0.258065  1.370192  0.164062  7.000000  6.835938  0.235948  female  \n",
       "3154  0.262295  0.718750  0.148438  7.000000  6.851562  0.092208  female  \n",
       "3155  0.253968  0.637921  0.148438  6.148438  6.000000  0.101291  female  \n",
       "3156  0.275862  0.593750  0.007812  5.921875  5.914062  0.124383  female  \n",
       "3157  0.262295  0.875558  0.171875  6.898438  6.726562  0.145534  female  \n",
       "3158  0.262295  0.550312  0.007812  3.421875  3.414062  0.166503  female  \n",
       "3159  0.271186  0.988281  0.007812  5.882812  5.875000  0.268617  female  \n",
       "3160  0.266667  0.766741  0.007812  4.007812  4.000000  0.192220  female  \n",
       "3161  0.253968  0.414062  0.007812  0.734375  0.726562  0.336918  female  \n",
       "3162  0.275862  0.533854  0.007812  2.992188  2.984375  0.258924  female  \n",
       "3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929  female  \n",
       "3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897  female  \n",
       "3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759  female  \n",
       "3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002  female  \n",
       "3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000  female  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('voice.csv', sep=',') \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Функция для замены строковых значений пола на цифровые\n",
    "def from_string2float(string):\n",
    "    if string == 'male':\n",
    "        string = 1\n",
    "        return string\n",
    "    else:\n",
    "        string = 0\n",
    "        return string\n",
    "\n",
    "#Применяем функцию обработки к столбцу пола\n",
    "df['label'] = df['label'].map(from_string2float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separation():    \n",
    "    #Ввод доли для разделения выборки на тестовую и обучающую\n",
    "    print('Введите долю выборки, которая будет тестовой от 0.1 до 0.9 (оптимальная работа если тестовая выборка меньше 0.5)')\n",
    "    while True:\n",
    "        try:\n",
    "            a = float(input())\n",
    "            if a>0.9 or a<0.1:\n",
    "                print('Введите цифру в заданном интервале')\n",
    "            else:\n",
    "                size_sep=a \n",
    "                break\n",
    "        except ValueError:\n",
    "            print('Введите цифру')\n",
    "    #Разделение выборки на тестовую и обучающую\n",
    "    train, test = train_test_split(df, test_size=size_sep)\n",
    "    tlearn=train.drop('label',axis=1)\n",
    "    ttrain=train['label']\n",
    "    check=test['label']\n",
    "    test=test.drop('label',axis=1)\n",
    "    return size_sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Блок классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def launch():\n",
    "    df = pd.read_csv('voice.csv', sep=',') \n",
    "    #Вывод названий алгоритмов для выбора пользователем\n",
    "    print(' Выберите номера желаемых методов классификации','\\n',\"1- Метод опорных векторов(SVR)\",'\\n','2- Cтохастический градиентный спуск(SGDRegressor)','\\n',\n",
    "    '3- Баесовская ridge регрессия (BayesianRidge)','\\n','4- Лассо модель с наименьшей угловой регрессией (LassoLars)','\\n',\n",
    "    '5- Баесовский Automatic Relevance Determination (RegressionARDRegression)','\\n', '6- AggressiveRegressor','\\n',\n",
    "    '7- Theil-Sen Estimator (TheilSenRegressor)','\\n','8- Линейная регрессия (LinearRegression)','\\n','9- К-ближайших соседей(KNeighborsClassifier)','\\n',\n",
    "    '10- Логистическая регрессия(LogisticRegression)')\n",
    "    b=[]\n",
    "    r = [1,2,3,4,5,6,7,8,9,10]\n",
    "    #Цикл для выбора пользователем алгоритмов\n",
    "    while True:\n",
    "        try:\n",
    "            a = input()\n",
    "            if a == '':\n",
    "                break\n",
    "            elif int(a) not in r or int(a) in b:\n",
    "                print('Введите цифру, соответствующую алгоритму. Цифры не должны повторяться')\n",
    "            else:\n",
    "                b.append(int(a))\n",
    "        except ValueError:\n",
    "            print('Введите цифру')\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Функция обучения алгоримов \n",
    "def engine(string):\n",
    "    predictions={}\n",
    "#     classifiers = [\n",
    "#         svm.SVR(),\n",
    "#         linear_model.SGDRegressor( penalty='elasticnet',fit_intercept=False),\n",
    "#         linear_model.BayesianRidge(),\n",
    "#         linear_model.LassoLars(),\n",
    "#         linear_model.ARDRegression(),\n",
    "#         linear_model.PassiveAggressiveRegressor(),\n",
    "#         linear_model.TheilSenRegressor(),\n",
    "#         linear_model.LinearRegression()]\n",
    "\n",
    "    trainingData    = tlearn\n",
    "    trainingScores  = ttrain\n",
    "    predictionData  = test\n",
    "\n",
    "    for i in tqdm.tqdm_notebook(string):\n",
    "        clf = list_of_algorithms[i]\n",
    "        clf.fit(trainingData, trainingScores)\n",
    "        predictions[list_of_algorithms[i]]=abs(np.around(clf.predict(predictionData)))\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\AAnaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\AAnaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Словарь алгоритмов\n",
    "list_of_algorithms={1:svm.SVR(), 2:linear_model.SGDRegressor(penalty='l1',loss='huber'), 3:linear_model.BayesianRidge(), 4:linear_model.LassoLars(normalize=True), \n",
    "     5:linear_model.ARDRegression(), 6:linear_model.PassiveAggressiveRegressor(), 7:linear_model.TheilSenRegressor(),\n",
    "     8:linear_model.LinearRegression(),9:KNeighborsClassifier(),10:LogisticRegression()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preparation(predictions):    \n",
    "    #Цикл для обработки значений предсказаний. Если значение >1, считаем, что это мужчина\n",
    "\n",
    "    for i,j in predictions.items():\n",
    "        for a in range(len(j)):\n",
    "            if predictions[i][a] > 1:\n",
    "                predictions[i][a]=1\n",
    "\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.78391167192429023, 0.4952681388012618, 0.95741324921135651, 0.4952681388012618, \n",
    " 0.95583596214511046, 0.49684542586750791, 0.94637223974763407, 0.95741324921135651]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация итогов классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualization(accuracy,entirety,Fmera,predictions):    \n",
    "    X = []\n",
    "    print(\" Данные были разделены в соотношении:\",\"\\n\",\"обучающая выборка\",1-size_sep,'и',size_sep, 'тестовая')\n",
    "    for i in range(len(predictions.keys())):\n",
    "        X.append(i+1)\n",
    "    plt.bar(X,accuracy,color='orange',xerr=0.55,ecolor='g')\n",
    "    plt.show()\n",
    "    c=1\n",
    "    for i in predictions.keys():\n",
    "        print(c,' - ',i,\"\\n\",\"\\n\",\"Точность данного алгортима= \",accuracy[c-1],\"\\n\",\"Полнота данного алгортима= \",entirety[c-1],'\\n',\n",
    "              \"Fмера данного алгортима= \",Fmera[c-1],'\\n')\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Главная функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Выберите номера желаемых методов классификации \n",
      " 1- Метод опорных векторов(SVR) \n",
      " 2- Cтохастический градиентный спуск(SGDRegressor) \n",
      " 3- Баесовская ridge регрессия (BayesianRidge) \n",
      " 4- Лассо модель с наименьшей угловой регрессией (LassoLars) \n",
      " 5- Баесовский Automatic Relevance Determination (RegressionARDRegression) \n",
      " 6- AggressiveRegressor \n",
      " 7- Theil-Sen Estimator (TheilSenRegressor) \n",
      " 8- Линейная регрессия (LinearRegression) \n",
      " 9- К-ближайших соседей(KNeighborsClassifier) \n",
      " 10- Логистическая регрессия(LogisticRegression)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "\n",
      "Введите долю выборки, которая будет тестовой от 0.1 до 0.9 (оптимальная работа если тестовая выборка меньше 0.5)\n",
      "0.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af5eb1f83754e7f90eb0466a9ac2166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Данные были разделены в соотношении: \n",
      " обучающая выборка 0.6 и 0.4 тестовая\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa9caa8c080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  -  SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      " \n",
      " Точность данного алгортима=  0.7917981072555205 \n",
      " Полнота данного алгортима=  0.7944969818913481 \n",
      " Fмера данного алгортима=  2.3834909456740445 \n",
      "\n",
      "2  -  SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
      "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "       loss='huber', max_iter=5, n_iter=None, penalty='l1', power_t=0.25,\n",
      "       random_state=None, shuffle=True, tol=None, verbose=0,\n",
      "       warm_start=False) \n",
      " \n",
      " Точность данного алгортима=  0.5141955835962145 \n",
      " Полнота данного алгортима=  0.6178517206477733 \n",
      " Fмера данного алгортима=  1.8535551619433197 \n",
      "\n",
      "3  -  BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "       normalize=False, tol=0.001, verbose=False) \n",
      " \n",
      " Точность данного алгортима=  0.9700315457413249 \n",
      " Полнота данного алгортима=  0.9700466792073492 \n",
      " Fмера данного алгортима=  2.910140037622048 \n",
      "\n",
      "4  -  LassoLars(alpha=1.0, copy_X=True, eps=2.2204460492503131e-16,\n",
      "     fit_intercept=True, fit_path=True, max_iter=500, normalize=True,\n",
      "     positive=False, precompute='auto', verbose=False) \n",
      " \n",
      " Точность данного алгортима=  0.4952681388012618 \n",
      " Полнота данного алгортима=  0.4952681388012618 \n",
      " Fмера данного алгортима=  1.4858044164037854 \n",
      "\n",
      "5  -  PassiveAggressiveRegressor(C=1.0, average=False, epsilon=0.1,\n",
      "              fit_intercept=True, loss='epsilon_insensitive', max_iter=5,\n",
      "              n_iter=None, random_state=None, shuffle=True, tol=None,\n",
      "              verbose=0, warm_start=False) \n",
      " \n",
      " Точность данного алгортима=  0.6577287066246057 \n",
      " Полнота данного алгортима=  0.6744732851079616 \n",
      " Fмера данного алгортима=  2.0234198553238847 \n",
      "\n",
      "6  -  TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=1, n_subsamples=None,\n",
      "         random_state=None, tol=0.001, verbose=False) \n",
      " \n",
      " Точность данного алгортима=  0.9479495268138801 \n",
      " Полнота данного алгортима=  0.9494399984014228 \n",
      " Fмера данного алгортима=  2.8483199952042684 \n",
      "\n",
      "7  -  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False) \n",
      " \n",
      " Точность данного алгортима=  0.9716088328075709 \n",
      " Полнота данного алгортима=  0.9716062898089173 \n",
      " Fмера данного алгортима=  2.914818869426752 \n",
      "\n",
      "8  -  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform') \n",
      " \n",
      " Точность данного алгортима=  0.7350157728706624 \n",
      " Полнота данного алгортима=  0.7368177799212281 \n",
      " Fмера данного алгортима=  2.210453339763684 \n",
      "\n",
      "9  -  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      " \n",
      " Точность данного алгортима=  0.9211356466876972 \n",
      " Полнота данного алгортима=  0.9270168135154797 \n",
      " Fмера данного алгортима=  2.781050440546439 \n",
      "\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Запуск программы\n",
    "algs = launch()\n",
    "\n",
    "#Выбор соотношения тестовой выборки и обучающей\n",
    "size_sep=separation()\n",
    "\n",
    "#Запуск классификации\n",
    "predictions = engine(algs)\n",
    "\n",
    "#Проверка на значение, превышающее 1\n",
    "predictions = preparation(predictions)\n",
    "\n",
    "#Обработка предсказанных значений\n",
    "accuracy,entirety,Fmera = pri(predictions,check)\n",
    "\n",
    "#Построение графиков\n",
    "visualization(accuracy,entirety,Fmera,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pri(predictions,check):\n",
    "    accuracy=[]\n",
    "    entirety=[]\n",
    "    Fmera=[]\n",
    "    num=0\n",
    "    for p in predictions.values():\n",
    "        predicted_values=[]\n",
    "        for j in p:\n",
    "            predicted_values.append(int(j))\n",
    "        true_walues=0\n",
    "        w_for_entirety=0\n",
    "        m_for_entirety=0\n",
    "        m=0\n",
    "        total_woman=0\n",
    "        for i in check.values:\n",
    "            if i == predicted_values[m]: \n",
    "                true_walues+=1 \n",
    "                m+=1\n",
    "            else: m+=1\n",
    "        accuracy.append(true_walues/len(predicted_values))\n",
    "        m=0\n",
    "        for i in check.values:\n",
    "            if i == predicted_values[m] and i == 0: \n",
    "                w_for_entirety+=1 \n",
    "                m+=1\n",
    "            else: m+=1\n",
    "        m=0\n",
    "        for i in check.values:\n",
    "            if i == predicted_values[m] and i == 1: \n",
    "                m_for_entirety+=1 \n",
    "                m+=1\n",
    "            else: m+=1\n",
    "        for i in predicted_values:\n",
    "            if i==0:\n",
    "                total_woman+=1\n",
    "        try:            \n",
    "            entirety.append((w_for_entirety/total_woman+(m_for_entirety/(len(predicted_values)-total_woman)))/2)\n",
    "        except ZeroDivisionError:\n",
    "            try:\n",
    "                entirety.append(w_for_entirety/total_woman)\n",
    "            except ZeroDivisionError:\n",
    "                entirety.append(0)\n",
    "        Fmera.append(accuracy[num]*entirety[num]*2/accuracy[num]+entirety[num])\n",
    "        num+=1\n",
    "    return accuracy,entirety,Fmera\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
